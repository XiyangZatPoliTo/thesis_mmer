from torch.utils.data import DataLoader
from collections import Counter
import matplotlib.pyplot as plt
import matplotlib
from dataset.dataset import RAVDESSMultimodalDataset
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
# è®¾ç½®å­—ä½“ä¸º SimHeiï¼Œä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
matplotlib.rcParams['font.family'] = 'SimHei'
# è§£å†³è´Ÿå· '-' æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
matplotlib.rcParams['axes.unicode_minus'] = False


# åˆå§‹åŒ– Dataset
dataset = RAVDESSMultimodalDataset(
    dataset_dir="F:/RAVDESS_dataset/Audio&Video_Speech_Actors_01-24/",
    mel_specs_kwargs={"n_mels": 128, "n_fft": 2048, "hop_length": 512},
    frames=15,
    verbose=True,
    debug=True
)

print(f"ğŸ” æ ·æœ¬æ€»æ•°: {len(dataset)}")

# æ‰‹åŠ¨å–ä¸€æ¡æ ·æœ¬
sample = dataset[0]
print("\nğŸ“¦ ç¬¬ä¸€ä¸ªæ ·æœ¬å†…å®¹ï¼š")
print("éŸ³é¢‘ç‰¹å¾ shape:", sample[0].shape)        # [128, T]
print("è§†é¢‘å¸§ shape:", sample[1].shape)          # [15, 3, 224, 224]
print("æ ‡ç­¾ç¼–å·:", sample[2].item())
print("æ ‡ç­¾å", sample[3])

# æ„å»º dataloader
loader = DataLoader(dataset, batch_size=8, shuffle=True)

# æ‰“å°å‰ä¸¤æ‰¹æ•°æ®
print("\nğŸ“¦ æŸ¥çœ‹å‰ä¸¤æ‰¹æ ·æœ¬çš„ç»“æ„ï¼š")
for i, batch in enumerate(loader):
    if len(batch) == 4:
        audio_batch, video_batch, label_batch, label_names = batch
    else:
        audio_batch, video_batch, label_batch = batch
        label_names = ["N/A"] * len(label_batch)

    print(f"\nBatch {i+1}")
    print("  audio batch shape:", audio_batch.shape)  # [B, 128, T]
    print("  video batch shape:", video_batch.shape)  # [B, 15, 3, 224, 224]
    print("  labels:", label_batch.tolist())
    print("  label names:", label_names)
    if i == 1:
        break

# ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
# NOTE: 'neutral' emotion (01) only has normal intensity (01),
#       so each actor has 4 neutral samples instead of 8,
#       leading to total 96 instead of 192.
print("\nğŸ“Š æ­£åœ¨ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ...")
labels = [dataset[i][2].item() for i in range(len(dataset))]
counter = Counter(labels)

# æ‰“å°æ ‡ç­¾åˆ†å¸ƒ
for k in sorted(counter.keys()):
    print(f"ç±» {k}: {counter[k]} ä¸ªæ ·æœ¬")

# å¯è§†åŒ–æ ‡ç­¾åˆ†å¸ƒ
plt.bar([str(k) for k in sorted(counter.keys())], [counter[k] for k in sorted(counter.keys())])
plt.xlabel("æƒ…ç»ªç±»åˆ«æ ‡ç­¾")
plt.ylabel("æ ·æœ¬æ•°")
plt.title("æ ‡ç­¾åˆ†å¸ƒç»Ÿè®¡")
plt.grid(True)
plt.show()





# import os
# from collections import defaultdict
#
# root_dir = "F:/RAVDESS_dataset/Audio&Video_Speech_Actors_01-24"
# video_counts = defaultdict(int)
# audio_counts = defaultdict(int)
#
# # éå†æ¯ä¸ªæ¼”å‘˜æ–‡ä»¶å¤¹
# for actor in sorted(os.listdir(root_dir)):
#     actor_path = os.path.join(root_dir, actor)
#     if not os.path.isdir(actor_path):
#         continue
#
#     for fname in os.listdir(actor_path):
#         if fname.startswith("02-") and fname.endswith("_facecropped.npy"):
#             video_counts[actor] += 1
#         elif fname.startswith("03-") and fname.endswith(".wav"):
#             audio_counts[actor] += 1
#
# # æ‰“å°ç»“æœ
# print("ğŸ¬ æ¯ä¸ªæ¼”å‘˜çš„ video-only (.npy) æ–‡ä»¶æ•° å’Œ audio-only (.wav) æ–‡ä»¶æ•°ï¼š\n")
# total_video, total_audio = 0, 0
# for actor in sorted(audio_counts.keys() | video_counts.keys()):
#     v = video_counts.get(actor, 0)
#     a = audio_counts.get(actor, 0)
#     total_video += v
#     total_audio += a
#     print(f"{actor}:  video-only .npy = {v:3d}    audio-only .wav = {a:3d}")
#
# print("\nğŸ“Š æ€»è®¡:")
# print(f"video-only .npy æ–‡ä»¶æ€»æ•°:  {total_video}")
# print(f"audio-only .wav æ–‡ä»¶æ€»æ•°:  {total_audio}")

